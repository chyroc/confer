package tag_parser

// Code generated by peg ./internal/tag_parser/tag.peg DO NOT EDIT.

import (
	"fmt"
	"io"
	"os"
	"sort"
	"strconv"
	"strings"
)

const endSymbol rune = 1114112

/* The rule types inferred from the grammar are below. */
type pegRule uint8

const (
	ruleUnknown pegRule = iota
	ruleDocument
	ruleExtractor
	ruleTransformer
	ruleOption
	ruleIdentifier
	ruleRequired
	ruleDefault
	ruleLetter
	ruleDigit
	ruleSkip
	ruleSpace
	ruleIndent
	ruleCarriageReturnLineFeed
	ruleCOMMA
	ruleEQUAL
	ruleREQUIRED
	ruleDEFAULT
	rulePegText
)

var rul3s = [...]string{
	"Unknown",
	"Document",
	"Extractor",
	"Transformer",
	"Option",
	"Identifier",
	"Required",
	"Default",
	"Letter",
	"Digit",
	"Skip",
	"Space",
	"Indent",
	"CarriageReturnLineFeed",
	"COMMA",
	"EQUAL",
	"REQUIRED",
	"DEFAULT",
	"PegText",
}

type token32 struct {
	pegRule
	begin, end uint32
}

func (t *token32) String() string {
	return fmt.Sprintf("\x1B[34m%v\x1B[m %v %v", rul3s[t.pegRule], t.begin, t.end)
}

type node32 struct {
	token32
	up, next *node32
}

func (node *node32) print(w io.Writer, pretty bool, buffer string) {
	var print func(node *node32, depth int)
	print = func(node *node32, depth int) {
		for node != nil {
			for c := 0; c < depth; c++ {
				fmt.Fprintf(w, " ")
			}
			rule := rul3s[node.pegRule]
			quote := strconv.Quote(string(([]rune(buffer)[node.begin:node.end])))
			if !pretty {
				fmt.Fprintf(w, "%v %v\n", rule, quote)
			} else {
				fmt.Fprintf(w, "\x1B[36m%v\x1B[m %v\n", rule, quote)
			}
			if node.up != nil {
				print(node.up, depth+1)
			}
			node = node.next
		}
	}
	print(node, 0)
}

func (node *node32) Print(w io.Writer, buffer string) {
	node.print(w, false, buffer)
}

func (node *node32) PrettyPrint(w io.Writer, buffer string) {
	node.print(w, true, buffer)
}

type tokens32 struct {
	tree []token32
}

func (t *tokens32) Trim(length uint32) {
	t.tree = t.tree[:length]
}

func (t *tokens32) Print() {
	for _, token := range t.tree {
		fmt.Println(token.String())
	}
}

func (t *tokens32) AST() *node32 {
	type element struct {
		node *node32
		down *element
	}
	tokens := t.Tokens()
	var stack *element
	for _, token := range tokens {
		if token.begin == token.end {
			continue
		}
		node := &node32{token32: token}
		for stack != nil && stack.node.begin >= token.begin && stack.node.end <= token.end {
			stack.node.next = node.up
			node.up = stack.node
			stack = stack.down
		}
		stack = &element{node: node, down: stack}
	}
	if stack != nil {
		return stack.node
	}
	return nil
}

func (t *tokens32) PrintSyntaxTree(buffer string) {
	t.AST().Print(os.Stdout, buffer)
}

func (t *tokens32) WriteSyntaxTree(w io.Writer, buffer string) {
	t.AST().Print(w, buffer)
}

func (t *tokens32) PrettyPrintSyntaxTree(buffer string) {
	t.AST().PrettyPrint(os.Stdout, buffer)
}

func (t *tokens32) Add(rule pegRule, begin, end, index uint32) {
	tree, i := t.tree, int(index)
	if i >= len(tree) {
		t.tree = append(tree, token32{pegRule: rule, begin: begin, end: end})
		return
	}
	tree[i] = token32{pegRule: rule, begin: begin, end: end}
}

func (t *tokens32) Tokens() []token32 {
	return t.tree
}

type TagParser struct {
	Buffer string
	buffer []rune
	rules  [19]func() bool
	parse  func(rule ...int) error
	reset  func()
	Pretty bool
	tokens32
}

func (p *TagParser) Parse(rule ...int) error {
	return p.parse(rule...)
}

func (p *TagParser) Reset() {
	p.reset()
}

type textPosition struct {
	line, symbol int
}

type textPositionMap map[int]textPosition

func translatePositions(buffer []rune, positions []int) textPositionMap {
	length, translations, j, line, symbol := len(positions), make(textPositionMap, len(positions)), 0, 1, 0
	sort.Ints(positions)

search:
	for i, c := range buffer {
		if c == '\n' {
			line, symbol = line+1, 0
		} else {
			symbol++
		}
		if i == positions[j] {
			translations[positions[j]] = textPosition{line, symbol}
			for j++; j < length; j++ {
				if i != positions[j] {
					continue search
				}
			}
			break search
		}
	}

	return translations
}

type parseError struct {
	p   *TagParser
	max token32
}

func (e *parseError) Error() string {
	tokens, err := []token32{e.max}, "\n"
	positions, p := make([]int, 2*len(tokens)), 0
	for _, token := range tokens {
		positions[p], p = int(token.begin), p+1
		positions[p], p = int(token.end), p+1
	}
	translations := translatePositions(e.p.buffer, positions)
	format := "parse error near %v (line %v symbol %v - line %v symbol %v):\n%v\n"
	if e.p.Pretty {
		format = "parse error near \x1B[34m%v\x1B[m (line %v symbol %v - line %v symbol %v):\n%v\n"
	}
	for _, token := range tokens {
		begin, end := int(token.begin), int(token.end)
		err += fmt.Sprintf(format,
			rul3s[token.pegRule],
			translations[begin].line, translations[begin].symbol,
			translations[end].line, translations[end].symbol,
			strconv.Quote(string(e.p.buffer[begin:end])))
	}

	return err
}

func (p *TagParser) PrintSyntaxTree() {
	if p.Pretty {
		p.tokens32.PrettyPrintSyntaxTree(p.Buffer)
	} else {
		p.tokens32.PrintSyntaxTree(p.Buffer)
	}
}

func (p *TagParser) WriteSyntaxTree(w io.Writer) {
	p.tokens32.WriteSyntaxTree(w, p.Buffer)
}

func (p *TagParser) SprintSyntaxTree() string {
	var bldr strings.Builder
	p.WriteSyntaxTree(&bldr)
	return bldr.String()
}

func Pretty(pretty bool) func(*TagParser) error {
	return func(p *TagParser) error {
		p.Pretty = pretty
		return nil
	}
}

func Size(size int) func(*TagParser) error {
	return func(p *TagParser) error {
		p.tokens32 = tokens32{tree: make([]token32, 0, size)}
		return nil
	}
}

func (p *TagParser) Init(options ...func(*TagParser) error) error {
	var (
		max                  token32
		position, tokenIndex uint32
		buffer               []rune
	)
	for _, option := range options {
		err := option(p)
		if err != nil {
			return err
		}
	}
	p.reset = func() {
		max = token32{}
		position, tokenIndex = 0, 0

		p.buffer = []rune(p.Buffer)
		if len(p.buffer) == 0 || p.buffer[len(p.buffer)-1] != endSymbol {
			p.buffer = append(p.buffer, endSymbol)
		}
		buffer = p.buffer
	}
	p.reset()

	_rules := p.rules
	tree := p.tokens32
	p.parse = func(rule ...int) error {
		r := 1
		if len(rule) > 0 {
			r = rule[0]
		}
		matches := p.rules[r]()
		p.tokens32 = tree
		if matches {
			p.Trim(tokenIndex)
			return nil
		}
		return &parseError{p, max}
	}

	add := func(rule pegRule, begin uint32) {
		tree.Add(rule, begin, position, tokenIndex)
		tokenIndex++
		if begin != position && position > max.end {
			max = token32{rule, begin, position}
		}
	}

	/*matchChar := func(c byte) bool {
		if buffer[position] == c {
			position++
			return true
		}
		return false
	}*/

	/*matchRange := func(lower byte, upper byte) bool {
		if c := buffer[position]; c >= lower && c <= upper {
			position++
			return true
		}
		return false
	}*/

	_rules = [...]func() bool{
		nil,
		/* 0 Document <- <((Extractor ';' Transformer ';' Option) / (Extractor ';' Transformer) / Extractor)> */
		func() bool {
			position0, tokenIndex0 := position, tokenIndex
			{
				position1 := position
				{
					position2, tokenIndex2 := position, tokenIndex
					if !_rules[ruleExtractor]() {
						goto l3
					}
					if buffer[position] != rune(';') {
						goto l3
					}
					position++
					if !_rules[ruleTransformer]() {
						goto l3
					}
					if buffer[position] != rune(';') {
						goto l3
					}
					position++
					if !_rules[ruleOption]() {
						goto l3
					}
					goto l2
				l3:
					position, tokenIndex = position2, tokenIndex2
					if !_rules[ruleExtractor]() {
						goto l4
					}
					if buffer[position] != rune(';') {
						goto l4
					}
					position++
					if !_rules[ruleTransformer]() {
						goto l4
					}
					goto l2
				l4:
					position, tokenIndex = position2, tokenIndex2
					if !_rules[ruleExtractor]() {
						goto l0
					}
				}
			l2:
				add(ruleDocument, position1)
			}
			return true
		l0:
			position, tokenIndex = position0, tokenIndex0
			return false
		},
		/* 1 Extractor <- <(Identifier (COMMA Identifier EQUAL Identifier)*)> */
		func() bool {
			position5, tokenIndex5 := position, tokenIndex
			{
				position6 := position
				if !_rules[ruleIdentifier]() {
					goto l5
				}
			l7:
				{
					position8, tokenIndex8 := position, tokenIndex
					if !_rules[ruleCOMMA]() {
						goto l8
					}
					if !_rules[ruleIdentifier]() {
						goto l8
					}
					if !_rules[ruleEQUAL]() {
						goto l8
					}
					if !_rules[ruleIdentifier]() {
						goto l8
					}
					goto l7
				l8:
					position, tokenIndex = position8, tokenIndex8
				}
				add(ruleExtractor, position6)
			}
			return true
		l5:
			position, tokenIndex = position5, tokenIndex5
			return false
		},
		/* 2 Transformer <- <(Identifier (COMMA Identifier EQUAL Identifier)*)> */
		func() bool {
			position9, tokenIndex9 := position, tokenIndex
			{
				position10 := position
				if !_rules[ruleIdentifier]() {
					goto l9
				}
			l11:
				{
					position12, tokenIndex12 := position, tokenIndex
					if !_rules[ruleCOMMA]() {
						goto l12
					}
					if !_rules[ruleIdentifier]() {
						goto l12
					}
					if !_rules[ruleEQUAL]() {
						goto l12
					}
					if !_rules[ruleIdentifier]() {
						goto l12
					}
					goto l11
				l12:
					position, tokenIndex = position12, tokenIndex12
				}
				add(ruleTransformer, position10)
			}
			return true
		l9:
			position, tokenIndex = position9, tokenIndex9
			return false
		},
		/* 3 Option <- <((Required / Default)? (COMMA (Required / Default))*)> */
		func() bool {
			{
				position14 := position
				{
					position15, tokenIndex15 := position, tokenIndex
					{
						position17, tokenIndex17 := position, tokenIndex
						if !_rules[ruleRequired]() {
							goto l18
						}
						goto l17
					l18:
						position, tokenIndex = position17, tokenIndex17
						if !_rules[ruleDefault]() {
							goto l15
						}
					}
				l17:
					goto l16
				l15:
					position, tokenIndex = position15, tokenIndex15
				}
			l16:
			l19:
				{
					position20, tokenIndex20 := position, tokenIndex
					if !_rules[ruleCOMMA]() {
						goto l20
					}
					{
						position21, tokenIndex21 := position, tokenIndex
						if !_rules[ruleRequired]() {
							goto l22
						}
						goto l21
					l22:
						position, tokenIndex = position21, tokenIndex21
						if !_rules[ruleDefault]() {
							goto l20
						}
					}
				l21:
					goto l19
				l20:
					position, tokenIndex = position20, tokenIndex20
				}
				add(ruleOption, position14)
			}
			return true
		},
		/* 4 Identifier <- <((Skip '"' <(Letter / Digit / Space / '.')*> '"' Indent*) / (Skip <(Letter / Digit / '.')*> Indent*))> */
		func() bool {
			position23, tokenIndex23 := position, tokenIndex
			{
				position24 := position
				{
					position25, tokenIndex25 := position, tokenIndex
					if !_rules[ruleSkip]() {
						goto l26
					}
					if buffer[position] != rune('"') {
						goto l26
					}
					position++
					{
						position27 := position
					l28:
						{
							position29, tokenIndex29 := position, tokenIndex
							{
								position30, tokenIndex30 := position, tokenIndex
								if !_rules[ruleLetter]() {
									goto l31
								}
								goto l30
							l31:
								position, tokenIndex = position30, tokenIndex30
								if !_rules[ruleDigit]() {
									goto l32
								}
								goto l30
							l32:
								position, tokenIndex = position30, tokenIndex30
								if !_rules[ruleSpace]() {
									goto l33
								}
								goto l30
							l33:
								position, tokenIndex = position30, tokenIndex30
								if buffer[position] != rune('.') {
									goto l29
								}
								position++
							}
						l30:
							goto l28
						l29:
							position, tokenIndex = position29, tokenIndex29
						}
						add(rulePegText, position27)
					}
					if buffer[position] != rune('"') {
						goto l26
					}
					position++
				l34:
					{
						position35, tokenIndex35 := position, tokenIndex
						if !_rules[ruleIndent]() {
							goto l35
						}
						goto l34
					l35:
						position, tokenIndex = position35, tokenIndex35
					}
					goto l25
				l26:
					position, tokenIndex = position25, tokenIndex25
					if !_rules[ruleSkip]() {
						goto l23
					}
					{
						position36 := position
					l37:
						{
							position38, tokenIndex38 := position, tokenIndex
							{
								position39, tokenIndex39 := position, tokenIndex
								if !_rules[ruleLetter]() {
									goto l40
								}
								goto l39
							l40:
								position, tokenIndex = position39, tokenIndex39
								if !_rules[ruleDigit]() {
									goto l41
								}
								goto l39
							l41:
								position, tokenIndex = position39, tokenIndex39
								if buffer[position] != rune('.') {
									goto l38
								}
								position++
							}
						l39:
							goto l37
						l38:
							position, tokenIndex = position38, tokenIndex38
						}
						add(rulePegText, position36)
					}
				l42:
					{
						position43, tokenIndex43 := position, tokenIndex
						if !_rules[ruleIndent]() {
							goto l43
						}
						goto l42
					l43:
						position, tokenIndex = position43, tokenIndex43
					}
				}
			l25:
				add(ruleIdentifier, position24)
			}
			return true
		l23:
			position, tokenIndex = position23, tokenIndex23
			return false
		},
		/* 5 Required <- <REQUIRED> */
		func() bool {
			position44, tokenIndex44 := position, tokenIndex
			{
				position45 := position
				if !_rules[ruleREQUIRED]() {
					goto l44
				}
				add(ruleRequired, position45)
			}
			return true
		l44:
			position, tokenIndex = position44, tokenIndex44
			return false
		},
		/* 6 Default <- <(DEFAULT EQUAL Identifier)> */
		func() bool {
			position46, tokenIndex46 := position, tokenIndex
			{
				position47 := position
				if !_rules[ruleDEFAULT]() {
					goto l46
				}
				if !_rules[ruleEQUAL]() {
					goto l46
				}
				if !_rules[ruleIdentifier]() {
					goto l46
				}
				add(ruleDefault, position47)
			}
			return true
		l46:
			position, tokenIndex = position46, tokenIndex46
			return false
		},
		/* 7 Letter <- <([A-Z] / [a-z] / '_')> */
		func() bool {
			position48, tokenIndex48 := position, tokenIndex
			{
				position49 := position
				{
					position50, tokenIndex50 := position, tokenIndex
					if c := buffer[position]; c < rune('A') || c > rune('Z') {
						goto l51
					}
					position++
					goto l50
				l51:
					position, tokenIndex = position50, tokenIndex50
					if c := buffer[position]; c < rune('a') || c > rune('z') {
						goto l52
					}
					position++
					goto l50
				l52:
					position, tokenIndex = position50, tokenIndex50
					if buffer[position] != rune('_') {
						goto l48
					}
					position++
				}
			l50:
				add(ruleLetter, position49)
			}
			return true
		l48:
			position, tokenIndex = position48, tokenIndex48
			return false
		},
		/* 8 Digit <- <[0-9]> */
		func() bool {
			position53, tokenIndex53 := position, tokenIndex
			{
				position54 := position
				if c := buffer[position]; c < rune('0') || c > rune('9') {
					goto l53
				}
				position++
				add(ruleDigit, position54)
			}
			return true
		l53:
			position, tokenIndex = position53, tokenIndex53
			return false
		},
		/* 9 Skip <- <Space*> */
		func() bool {
			{
				position56 := position
			l57:
				{
					position58, tokenIndex58 := position, tokenIndex
					if !_rules[ruleSpace]() {
						goto l58
					}
					goto l57
				l58:
					position, tokenIndex = position58, tokenIndex58
				}
				add(ruleSkip, position56)
			}
			return true
		},
		/* 10 Space <- <(Indent / CarriageReturnLineFeed)+> */
		func() bool {
			position59, tokenIndex59 := position, tokenIndex
			{
				position60 := position
				{
					position63, tokenIndex63 := position, tokenIndex
					if !_rules[ruleIndent]() {
						goto l64
					}
					goto l63
				l64:
					position, tokenIndex = position63, tokenIndex63
					if !_rules[ruleCarriageReturnLineFeed]() {
						goto l59
					}
				}
			l63:
			l61:
				{
					position62, tokenIndex62 := position, tokenIndex
					{
						position65, tokenIndex65 := position, tokenIndex
						if !_rules[ruleIndent]() {
							goto l66
						}
						goto l65
					l66:
						position, tokenIndex = position65, tokenIndex65
						if !_rules[ruleCarriageReturnLineFeed]() {
							goto l62
						}
					}
				l65:
					goto l61
				l62:
					position, tokenIndex = position62, tokenIndex62
				}
				add(ruleSpace, position60)
			}
			return true
		l59:
			position, tokenIndex = position59, tokenIndex59
			return false
		},
		/* 11 Indent <- <(' ' / '\t' / '\v')> */
		func() bool {
			position67, tokenIndex67 := position, tokenIndex
			{
				position68 := position
				{
					position69, tokenIndex69 := position, tokenIndex
					if buffer[position] != rune(' ') {
						goto l70
					}
					position++
					goto l69
				l70:
					position, tokenIndex = position69, tokenIndex69
					if buffer[position] != rune('\t') {
						goto l71
					}
					position++
					goto l69
				l71:
					position, tokenIndex = position69, tokenIndex69
					if buffer[position] != rune('\v') {
						goto l67
					}
					position++
				}
			l69:
				add(ruleIndent, position68)
			}
			return true
		l67:
			position, tokenIndex = position67, tokenIndex67
			return false
		},
		/* 12 CarriageReturnLineFeed <- <('\r' / '\n')> */
		func() bool {
			position72, tokenIndex72 := position, tokenIndex
			{
				position73 := position
				{
					position74, tokenIndex74 := position, tokenIndex
					if buffer[position] != rune('\r') {
						goto l75
					}
					position++
					goto l74
				l75:
					position, tokenIndex = position74, tokenIndex74
					if buffer[position] != rune('\n') {
						goto l72
					}
					position++
				}
			l74:
				add(ruleCarriageReturnLineFeed, position73)
			}
			return true
		l72:
			position, tokenIndex = position72, tokenIndex72
			return false
		},
		/* 13 COMMA <- <(Skip ',' Indent*)> */
		func() bool {
			position76, tokenIndex76 := position, tokenIndex
			{
				position77 := position
				if !_rules[ruleSkip]() {
					goto l76
				}
				if buffer[position] != rune(',') {
					goto l76
				}
				position++
			l78:
				{
					position79, tokenIndex79 := position, tokenIndex
					if !_rules[ruleIndent]() {
						goto l79
					}
					goto l78
				l79:
					position, tokenIndex = position79, tokenIndex79
				}
				add(ruleCOMMA, position77)
			}
			return true
		l76:
			position, tokenIndex = position76, tokenIndex76
			return false
		},
		/* 14 EQUAL <- <(Skip '=' Indent*)> */
		func() bool {
			position80, tokenIndex80 := position, tokenIndex
			{
				position81 := position
				if !_rules[ruleSkip]() {
					goto l80
				}
				if buffer[position] != rune('=') {
					goto l80
				}
				position++
			l82:
				{
					position83, tokenIndex83 := position, tokenIndex
					if !_rules[ruleIndent]() {
						goto l83
					}
					goto l82
				l83:
					position, tokenIndex = position83, tokenIndex83
				}
				add(ruleEQUAL, position81)
			}
			return true
		l80:
			position, tokenIndex = position80, tokenIndex80
			return false
		},
		/* 15 REQUIRED <- <(Skip ('r' 'e' 'q' 'u' 'i' 'r' 'e' 'd') Indent*)> */
		func() bool {
			position84, tokenIndex84 := position, tokenIndex
			{
				position85 := position
				if !_rules[ruleSkip]() {
					goto l84
				}
				if buffer[position] != rune('r') {
					goto l84
				}
				position++
				if buffer[position] != rune('e') {
					goto l84
				}
				position++
				if buffer[position] != rune('q') {
					goto l84
				}
				position++
				if buffer[position] != rune('u') {
					goto l84
				}
				position++
				if buffer[position] != rune('i') {
					goto l84
				}
				position++
				if buffer[position] != rune('r') {
					goto l84
				}
				position++
				if buffer[position] != rune('e') {
					goto l84
				}
				position++
				if buffer[position] != rune('d') {
					goto l84
				}
				position++
			l86:
				{
					position87, tokenIndex87 := position, tokenIndex
					if !_rules[ruleIndent]() {
						goto l87
					}
					goto l86
				l87:
					position, tokenIndex = position87, tokenIndex87
				}
				add(ruleREQUIRED, position85)
			}
			return true
		l84:
			position, tokenIndex = position84, tokenIndex84
			return false
		},
		/* 16 DEFAULT <- <(Skip ('d' 'e' 'f' 'a' 'u' 'l' 't') Indent*)> */
		func() bool {
			position88, tokenIndex88 := position, tokenIndex
			{
				position89 := position
				if !_rules[ruleSkip]() {
					goto l88
				}
				if buffer[position] != rune('d') {
					goto l88
				}
				position++
				if buffer[position] != rune('e') {
					goto l88
				}
				position++
				if buffer[position] != rune('f') {
					goto l88
				}
				position++
				if buffer[position] != rune('a') {
					goto l88
				}
				position++
				if buffer[position] != rune('u') {
					goto l88
				}
				position++
				if buffer[position] != rune('l') {
					goto l88
				}
				position++
				if buffer[position] != rune('t') {
					goto l88
				}
				position++
			l90:
				{
					position91, tokenIndex91 := position, tokenIndex
					if !_rules[ruleIndent]() {
						goto l91
					}
					goto l90
				l91:
					position, tokenIndex = position91, tokenIndex91
				}
				add(ruleDEFAULT, position89)
			}
			return true
		l88:
			position, tokenIndex = position88, tokenIndex88
			return false
		},
		nil,
	}
	p.rules = _rules
	return nil
}
